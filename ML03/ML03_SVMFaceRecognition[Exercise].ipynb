{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition with Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In this notebook, we show how to perform face recognition using Support Vector Machines. We will use the Olivetti faces dataset, included in Scikit-learn. More info at: http://scikit-learn.org/stable/datasets/olivetti_faces.html_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing numpy, scikit-learn, and matplotlib, the Python libraries we will be using in this chapter. Show the versions we will be using (in case you have problems running the notebooks) and use the inline plotting mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.12.1\npandas version: 0.20.1\nscikit-le version: 0.18.1\nmatplotlib version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np      \n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('numpy version:', np.__version__)\n",
    "print('pandas version:', pd.__version__)\n",
    "print('scikit-le version:', sk.__version__)\n",
    "print('matplotlib version:', matplotlib.__version__)\n",
    "\n",
    "\n",
    "%matplotlib inline   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Olivetti Face dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the olivetti faces dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Olivetti faces dataset.\n\nThe original database was available from\n\n    http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n\nThe version retrieved here comes in MATLAB format from the personal\nweb page of Sam Roweis:\n\n    http://www.cs.nyu.edu/~roweis/\n\nThere are ten different images of each of 40 distinct subjects. For some\nsubjects, the images were taken at different times, varying the lighting,\nfacial expressions (open / closed eyes, smiling / not smiling) and facial\ndetails (glasses / no glasses). All the images were taken against a dark\nhomogeneous background with the subjects in an upright, frontal position (with\ntolerance for some side movement).\n\nThe original dataset consisted of 92 x 112, while the Roweis version\nconsists of 64x64 images.\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "# Fetch the faces data\n",
    "faces = fetch_olivetti_faces()\n",
    "\n",
    "print(faces.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Investigate the Olivetti Face DatasetÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data, faces.images has 400 images of faces, each one is composed by a matrix of 64x64 pixels.\n",
    "faces.data has the same data but in rows of 4096 attributes instead of matrices (4096 = 64x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'images', 'target', 'DESCR'])\n(400, 64, 64)\n(400, 4096)\n(400,)\n[ 0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2\n  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4\n  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7\n  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9\n 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12\n 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14\n 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17\n 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19\n 20 20 20 20 20 20 20 20 20 20 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22\n 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24\n 25 25 25 25 25 25 25 25 25 25 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27\n 27 27 27 27 27 28 28 28 28 28 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29\n 30 30 30 30 30 30 30 30 30 30 31 31 31 31 31 31 31 31 31 31 32 32 32 32 32\n 32 32 32 32 32 33 33 33 33 33 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34\n 35 35 35 35 35 35 35 35 35 35 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37\n 37 37 37 37 37 38 38 38 38 38 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39]\n"
     ]
    }
   ],
   "source": [
    "print(faces.keys())\n",
    "print(faces.images.shape)\n",
    "print(faces.data.shape)\n",
    "print(faces.target.shape)\n",
    "\n",
    "print(faces.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to scale attributes, because data is already normalized (between 0 and 1). optional: can you prove this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30991736,  0.36776859,  0.41735536, ...,  0.15289256,\n         0.16115703,  0.1570248 ],\n       [ 0.45454547,  0.47107437,  0.51239669, ...,  0.15289256,\n         0.15289256,  0.15289256],\n       [ 0.31818181,  0.40082645,  0.49173555, ...,  0.14049587,\n         0.14876033,  0.15289256],\n       ..., \n       [ 0.5       ,  0.53305787,  0.60743803, ...,  0.17768595,\n         0.14876033,  0.19008264],\n       [ 0.21487603,  0.21900827,  0.21900827, ...,  0.57438016,\n         0.59090906,  0.60330576],\n       [ 0.5165289 ,  0.46280992,  0.28099173, ...,  0.35950413,\n         0.35537189,  0.38429752]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces.data\n",
    "\n",
    "# If we look at this data it is obvious that the data is nomalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the faces in a matrix of 20x20, for each one, we'll put the target value in the top left corner and it's index in the bottom left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(25):\n",
    "    face = faces.images[i]\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(face.reshape((64, 64)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Analysis with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to build a classifier whose model is a hyperplane that separates instances (points) of one class from the rest. Support Vector Machines (SVM) are supervised learning methods that try to obtain these hyperplanes in an optimal way, by selecting the ones that pass through the widest possible gaps between instances of different classes. New instances will be classified as belonging to a certain category based on which side of the surfaces they fall on. Let's import the SVC class from the sklearn.svm module. SVC stands for Support Vector Classifier: we will use SVM for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_1 = SVC(kernel='linear')\n",
    "print(svc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Build training and testing sets and perform 5-fold cross-validation (use the ``from sklearn.model_selection`` package for this). Show what all the accuracy scores are and compute the average value. Consult the sklearn documentation and when needed ask your teacher for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93333333  0.86666667  0.91666667  0.93333333  0.91666667]\nMean score: 0.913 (+/-0.012)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_1 = SVC(kernel='linear')\n",
    "data = faces.data\n",
    "target = faces.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=0)\n",
    "\n",
    "# 5 fold cross validation\n",
    "cv = KFold(len(y_train), 5, shuffle=True, random_state=0)\n",
    "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "scores = cross_val_score(svc_1, x_train, y_train, cv=cv)\n",
    "print (scores)\n",
    "print (\"Mean score: {0:.3f} (+/-{1:.3f})\".format(\n",
    "        np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Other Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the sklearn ``metrics`` package and determine also precision and recall for the test set, for _each class_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n\n          0       0.86      1.00      0.92         6\n          1       1.00      1.00      1.00         4\n          2       1.00      1.00      1.00         2\n          3       1.00      1.00      1.00         1\n          4       1.00      1.00      1.00         1\n          5       1.00      1.00      1.00         5\n          6       1.00      1.00      1.00         4\n          7       1.00      0.67      0.80         3\n          9       1.00      1.00      1.00         1\n         10       1.00      1.00      1.00         4\n         11       1.00      1.00      1.00         1\n         12       1.00      1.00      1.00         2\n         13       1.00      1.00      1.00         3\n         14       1.00      1.00      1.00         5\n         15       1.00      1.00      1.00         3\n         17       1.00      1.00      1.00         6\n         19       1.00      1.00      1.00         4\n         20       1.00      1.00      1.00         1\n         21       1.00      1.00      1.00         1\n         22       1.00      1.00      1.00         2\n         23       1.00      1.00      1.00         1\n         24       1.00      1.00      1.00         2\n         25       1.00      1.00      1.00         2\n         26       1.00      1.00      1.00         4\n         27       1.00      1.00      1.00         1\n         28       1.00      1.00      1.00         2\n         29       1.00      1.00      1.00         3\n         30       1.00      1.00      1.00         4\n         31       1.00      1.00      1.00         3\n         32       1.00      1.00      1.00         3\n         33       1.00      1.00      1.00         2\n         34       1.00      1.00      1.00         3\n         35       1.00      1.00      1.00         1\n         36       1.00      1.00      1.00         3\n         37       1.00      1.00      1.00         3\n         38       1.00      1.00      1.00         1\n         39       1.00      1.00      1.00         3\n\navg / total       0.99      0.99      0.99       100\n\n[[6 0 0 ..., 0 0 0]\n [0 4 0 ..., 0 0 0]\n [0 0 2 ..., 0 0 0]\n ..., \n [0 0 0 ..., 3 0 0]\n [0 0 0 ..., 0 1 0]\n [0 0 0 ..., 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "svc_1.fit(x_train, y_train)\n",
    "y_pred = svc_1.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "# The confusion matrix gives insight on the errors that the classifier made during training\n",
    "print (metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure precision and recall on the evaluation set, for _each class_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n\n          0       1.00      1.00      1.00         4\n          1       1.00      1.00      1.00         6\n          2       1.00      1.00      1.00         8\n          3       1.00      1.00      1.00         9\n          4       1.00      1.00      1.00         9\n          5       1.00      1.00      1.00         5\n          6       1.00      1.00      1.00         6\n          7       1.00      1.00      1.00         7\n          8       1.00      1.00      1.00        10\n          9       1.00      1.00      1.00         9\n         10       1.00      1.00      1.00         6\n         11       1.00      1.00      1.00         9\n         12       1.00      1.00      1.00         8\n         13       1.00      1.00      1.00         7\n         14       1.00      1.00      1.00         5\n         15       1.00      1.00      1.00         7\n         16       1.00      1.00      1.00        10\n         17       1.00      1.00      1.00         4\n         18       1.00      1.00      1.00        10\n         19       1.00      1.00      1.00         6\n         20       1.00      1.00      1.00         9\n         21       1.00      1.00      1.00         9\n         22       1.00      1.00      1.00         8\n         23       1.00      1.00      1.00         9\n         24       1.00      1.00      1.00         8\n         25       1.00      1.00      1.00         8\n         26       1.00      1.00      1.00         6\n         27       1.00      1.00      1.00         9\n         28       1.00      1.00      1.00         8\n         29       1.00      1.00      1.00         7\n         30       1.00      1.00      1.00         6\n         31       1.00      1.00      1.00         7\n         32       1.00      1.00      1.00         7\n         33       1.00      1.00      1.00         8\n         34       1.00      1.00      1.00         7\n         35       1.00      1.00      1.00         9\n         36       1.00      1.00      1.00         7\n         37       1.00      1.00      1.00         7\n         38       1.00      1.00      1.00         9\n         39       1.00      1.00      1.00         7\n\navg / total       1.00      1.00      1.00       300\n\n[[4 0 0 ..., 0 0 0]\n [0 6 0 ..., 0 0 0]\n [0 0 8 ..., 0 0 0]\n ..., \n [0 0 0 ..., 7 0 0]\n [0 0 0 ..., 0 9 0]\n [0 0 0 ..., 0 0 7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = svc_1.predict(x_train)\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "# The confusion matrix gives insight on the errors that the classifier made during training\n",
    "print (metrics.confusion_matrix(y_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion performance of SVM for face recognition is incredibly high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Discriminate People with or without Glasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, another problem: Let's try to classify images of people with and without glasses. Mark people with glasses as 1 and people without glasses as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I have created another script which made it easy to classify the images. You can find it in this same folder called 'GlassesClassifier\". The results can be found in resultsGlassesNoGlasses.xml\n",
    "from pylab import *\n",
    "import json\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()  # Get current directory because the normal path doesn't work with notebook.\n",
    "target = json.load(open(cwd + '/ML03/resultsGlassesNoGlasses.xml'))\n",
    "target = [target[i] for i in target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test set for the new problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_1 = SVC(kernel='linear')\n",
    "data = faces.data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try again with a linear SVM kernel and show a classification report as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.95        0.98333333  0.98333333  0.93333333]\nMean score: 0.970 (+/-0.012)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5 fold cross validation\n",
    "cv = KFold(len(y_train), 5, shuffle=True, random_state=0)\n",
    "# by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "scores = cross_val_score(svc_1, x_train, y_train, cv=cv)\n",
    "print (scores)\n",
    "print (\"Mean score: {0:.3f} (+/-{1:.3f})\".format(\n",
    "        np.mean(scores), sem(scores)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
